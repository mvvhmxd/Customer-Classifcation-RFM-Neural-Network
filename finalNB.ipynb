{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Classification of Online Retail Customers Using Neural Networks\n",
        "\n",
        "## CSE 5632 - Neural Networks Course Project\n",
        "\n",
        "This notebook implements customer classification using RFM (Recency, Frequency, Monetary) analysis and compares multiple machine learning models:\n",
        "- Neural Network (Multi-Layer Perceptron)\n",
        "- Gradient Boosting Classifier\n",
        "- Random Forest Classifier\n",
        "\n",
        "**Dataset:** UCI Online Retail Dataset"
      ],
      "metadata": {
        "id": "header_cell"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Import Libraries"
      ],
      "metadata": {
        "id": "section_1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imports"
      },
      "outputs": [],
      "source": [
        "# Data Manipulation & Visualization\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import datetime as dt\n",
        "\n",
        "# Preprocessing & Clustering\n",
        "from sklearn.preprocessing import StandardScaler, label_binarize\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Model Selection & Metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    classification_report, accuracy_score, confusion_matrix,\n",
        "    roc_curve, auc, f1_score, precision_score, recall_score\n",
        ")\n",
        "\n",
        "# Classification Models\n",
        "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
        "\n",
        "# Neural Network\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Settings\n",
        "pd.set_option('display.max_columns', None)\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"All libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Load Dataset"
      ],
      "metadata": {
        "id": "section_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Online Retail Dataset\n",
        "# Note: Update the file path if running in a different environment\n",
        "file_path = 'Online Retail.xlsx'\n",
        "\n",
        "df = pd.read_excel(file_path)\n",
        "print(f\"Original Data Shape: {df.shape}\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "load_data"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Data Preprocessing"
      ],
      "metadata": {
        "id": "section_3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize column names\n",
        "df.rename(columns={\n",
        "    'InvoiceNo': 'Invoice',\n",
        "    'CustomerID': 'Customer ID',\n",
        "    'UnitPrice': 'Price'\n",
        "}, inplace=True)\n",
        "\n",
        "# Drop rows with null Customer ID\n",
        "df = df.dropna(subset=['Customer ID'])\n",
        "\n",
        "# Remove duplicate entries\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "# Remove cancelled orders (invoices starting with 'C')\n",
        "df['Invoice'] = df['Invoice'].astype(str)\n",
        "df = df[~df['Invoice'].str.startswith('C')]\n",
        "\n",
        "print(f\"Data Shape after cleaning: {df.shape}\")\n",
        "print(f\"Number of unique customers: {df['Customer ID'].nunique()}\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "preprocessing"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. RFM Feature Engineering"
      ],
      "metadata": {
        "id": "section_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate total transaction value\n",
        "df['TotalSum'] = df['Quantity'] * df['Price']\n",
        "\n",
        "# Set snapshot date for Recency calculation\n",
        "snapshot_date = df['InvoiceDate'].max() + dt.timedelta(days=1)\n",
        "print(f\"Snapshot Date: {snapshot_date}\")\n",
        "\n",
        "# Aggregate data by Customer ID to compute RFM metrics\n",
        "rfm = df.groupby(['Customer ID']).agg({\n",
        "    'InvoiceDate': lambda x: (snapshot_date - x.max()).days,  # Recency\n",
        "    'Invoice': 'nunique',                                      # Frequency\n",
        "    'TotalSum': 'sum'                                          # Monetary\n",
        "})\n",
        "\n",
        "# Rename columns\n",
        "rfm.rename(columns={\n",
        "    'InvoiceDate': 'Recency',\n",
        "    'Invoice': 'Frequency',\n",
        "    'TotalSum': 'Monetary'\n",
        "}, inplace=True)\n",
        "\n",
        "# Filter to ensure positive monetary values\n",
        "rfm = rfm[rfm['Monetary'] > 0]\n",
        "\n",
        "print(f\"RFM Table Shape: {rfm.shape}\")\n",
        "rfm.head()"
      ],
      "metadata": {
        "id": "rfm_calculation"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply Log Transformation and Standard Scaling\n",
        "rfm_log = np.log(rfm + 1)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "rfm_scaled = scaler.fit_transform(rfm_log)\n",
        "\n",
        "rfm_scaled_df = pd.DataFrame(rfm_scaled, index=rfm.index, columns=rfm.columns)\n",
        "print(\"Data Preprocessed (Log + Scaled) successfully!\")\n",
        "rfm_scaled_df.head()"
      ],
      "metadata": {
        "id": "rfm_preprocessing"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Customer Segmentation using K-Means Clustering"
      ],
      "metadata": {
        "id": "section_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply K-Means Clustering with 3 clusters (Low, Mid, High value)\n",
        "kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
        "kmeans.fit(rfm_scaled_df)\n",
        "\n",
        "rfm['Cluster'] = kmeans.labels_\n",
        "\n",
        "# Order clusters by monetary value (0=Low, 1=Mid, 2=High)\n",
        "cluster_mapping = rfm.groupby('Cluster')['Monetary'].mean().sort_values().index\n",
        "mapping_dict = {old_label: new_label for new_label, old_label in enumerate(cluster_mapping)}\n",
        "rfm['Cluster'] = rfm['Cluster'].map(mapping_dict)\n",
        "\n",
        "# Display cluster summary\n",
        "cluster_summary = rfm.groupby('Cluster').agg({\n",
        "    'Recency': 'mean',\n",
        "    'Frequency': 'mean',\n",
        "    'Monetary': 'mean',\n",
        "    'Cluster': 'count'\n",
        "}).rename(columns={'Cluster': 'Count'})\n",
        "\n",
        "print(\"Cluster Summary (0=Low, 1=Mid, 2=High):\")\n",
        "display(cluster_summary.round(2))\n",
        "\n",
        "rfm_scaled_df['Cluster'] = rfm['Cluster']"
      ],
      "metadata": {
        "id": "kmeans_clustering"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. 3D Visualization of Customer Segments"
      ],
      "metadata": {
        "id": "section_6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "\n",
        "rfm_vis = rfm.copy()\n",
        "rfm_vis['Cluster_Label'] = rfm['Cluster'].map({0: 'Low', 1: 'Mid', 2: 'High'})\n",
        "\n",
        "fig = px.scatter_3d(\n",
        "    rfm_vis, x='Recency', y='Frequency', z='Monetary',\n",
        "    color='Cluster_Label',\n",
        "    title='3D View of Customer Segments',\n",
        "    opacity=0.7,\n",
        "    color_discrete_map={'Low': 'red', 'Mid': 'blue', 'High': 'green'}\n",
        ")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "3d_visualization"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Prepare Data for Classification"
      ],
      "metadata": {
        "id": "section_7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Features (X) and Target (y)\n",
        "X = rfm_scaled_df.drop('Cluster', axis=1)\n",
        "y = rfm_scaled_df['Cluster']\n",
        "\n",
        "# Split the data (80% Train, 20% Test) with stratification\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"Training Data: {X_train.shape}\")\n",
        "print(f\"Testing Data: {X_test.shape}\")\n",
        "print(f\"\\nClass Distribution in Training Set:\")\n",
        "print(y_train.value_counts().sort_index())"
      ],
      "metadata": {
        "id": "train_test_split"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Model Training\n",
        "\n",
        "### 8.1 Neural Network (Multi-Layer Perceptron)"
      ],
      "metadata": {
        "id": "section_8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare target for Neural Network (One-Hot Encoding)\n",
        "y_train_cat = to_categorical(y_train)\n",
        "y_test_cat = to_categorical(y_test)\n",
        "\n",
        "# Build the Neural Network Architecture\n",
        "model_nn = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dropout(0.2),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the Model\n",
        "model_nn.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Train the Model\n",
        "print(\"Training Neural Network...\")\n",
        "history = model_nn.fit(\n",
        "    X_train, y_train_cat,\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Get predictions\n",
        "y_pred_nn_prob = model_nn.predict(X_test)\n",
        "y_pred_nn = np.argmax(y_pred_nn_prob, axis=1)\n",
        "\n",
        "nn_accuracy = accuracy_score(y_test, y_pred_nn)\n",
        "print(f\"\\nNeural Network Test Accuracy: {nn_accuracy*100:.2f}%\")"
      ],
      "metadata": {
        "id": "neural_network"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8.2 Gradient Boosting Classifier"
      ],
      "metadata": {
        "id": "section_8_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Gradient Boosting Classifier\n",
        "print(\"Training Gradient Boosting Classifier...\")\n",
        "model_gb = GradientBoostingClassifier(\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=5,\n",
        "    random_state=42\n",
        ")\n",
        "model_gb.fit(X_train, y_train)\n",
        "\n",
        "# Get predictions\n",
        "y_pred_gb = model_gb.predict(X_test)\n",
        "y_pred_gb_prob = model_gb.predict_proba(X_test)\n",
        "\n",
        "gb_accuracy = accuracy_score(y_test, y_pred_gb)\n",
        "print(f\"Gradient Boosting Test Accuracy: {gb_accuracy*100:.2f}%\")"
      ],
      "metadata": {
        "id": "gradient_boosting"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8.3 Random Forest Classifier"
      ],
      "metadata": {
        "id": "section_8_3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Random Forest Classifier\n",
        "print(\"Training Random Forest Classifier...\")\n",
        "model_rf = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=10,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "model_rf.fit(X_train, y_train)\n",
        "\n",
        "# Get predictions\n",
        "y_pred_rf = model_rf.predict(X_test)\n",
        "y_pred_rf_prob = model_rf.predict_proba(X_test)\n",
        "\n",
        "rf_accuracy = accuracy_score(y_test, y_pred_rf)\n",
        "print(f\"Random Forest Test Accuracy: {rf_accuracy*100:.2f}%\")"
      ],
      "metadata": {
        "id": "random_forest"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Model Evaluation\n",
        "\n",
        "### 9.1 Classification Reports"
      ],
      "metadata": {
        "id": "section_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification Report for all models\n",
        "class_names = ['Low Value', 'Mid Value', 'High Value']\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"NEURAL NETWORK - Classification Report\")\n",
        "print(\"=\" * 60)\n",
        "print(classification_report(y_test, y_pred_nn, target_names=class_names))\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"GRADIENT BOOSTING - Classification Report\")\n",
        "print(\"=\" * 60)\n",
        "print(classification_report(y_test, y_pred_gb, target_names=class_names))\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"RANDOM FOREST - Classification Report\")\n",
        "print(\"=\" * 60)\n",
        "print(classification_report(y_test, y_pred_rf, target_names=class_names))"
      ],
      "metadata": {
        "id": "classification_reports"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9.2 Confusion Matrices"
      ],
      "metadata": {
        "id": "section_9_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Confusion Matrices for all models\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "models = [\n",
        "    ('Neural Network', y_pred_nn),\n",
        "    ('Gradient Boosting', y_pred_gb),\n",
        "    ('Random Forest', y_pred_rf)\n",
        "]\n",
        "\n",
        "for ax, (name, y_pred) in zip(axes, models):\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    sns.heatmap(\n",
        "        cm, annot=True, fmt='d', cmap='Blues', ax=ax,\n",
        "        xticklabels=class_names, yticklabels=class_names\n",
        "    )\n",
        "    ax.set_title(f'{name}\\nAccuracy: {accuracy_score(y_test, y_pred)*100:.2f}%')\n",
        "    ax.set_ylabel('True Label')\n",
        "    ax.set_xlabel('Predicted Label')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('confusion_matrices.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "confusion_matrices"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9.3 ROC Curves and AUC Scores"
      ],
      "metadata": {
        "id": "section_9_3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Binarize the labels for multi-class ROC\n",
        "n_classes = 3\n",
        "y_test_bin = label_binarize(y_test, classes=[0, 1, 2])\n",
        "\n",
        "# Calculate ROC curves for each model and class\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "models_prob = [\n",
        "    ('Neural Network', y_pred_nn_prob),\n",
        "    ('Gradient Boosting', y_pred_gb_prob),\n",
        "    ('Random Forest', y_pred_rf_prob)\n",
        "]\n",
        "\n",
        "colors = ['red', 'blue', 'green']\n",
        "\n",
        "for ax, (model_name, y_prob) in zip(axes, models_prob):\n",
        "    auc_scores = []\n",
        "    for i in range(n_classes):\n",
        "        fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_prob[:, i])\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        auc_scores.append(roc_auc)\n",
        "        ax.plot(fpr, tpr, color=colors[i], lw=2,\n",
        "                label=f'{class_names[i]} (AUC = {roc_auc:.3f})')\n",
        "\n",
        "    ax.plot([0, 1], [0, 1], 'k--', lw=2)\n",
        "    ax.set_xlim([0.0, 1.0])\n",
        "    ax.set_ylim([0.0, 1.05])\n",
        "    ax.set_xlabel('False Positive Rate')\n",
        "    ax.set_ylabel('True Positive Rate')\n",
        "    ax.set_title(f'{model_name}\\nMean AUC: {np.mean(auc_scores):.3f}')\n",
        "    ax.legend(loc='lower right')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('roc_curves.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "roc_curves"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9.4 Model Performance Comparison"
      ],
      "metadata": {
        "id": "section_9_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate metrics for each model\n",
        "def calculate_metrics(y_true, y_pred):\n",
        "    return {\n",
        "        'Accuracy': accuracy_score(y_true, y_pred),\n",
        "        'F1 (Macro)': f1_score(y_true, y_pred, average='macro'),\n",
        "        'F1 (Weighted)': f1_score(y_true, y_pred, average='weighted'),\n",
        "        'Precision (Macro)': precision_score(y_true, y_pred, average='macro'),\n",
        "        'Recall (Macro)': recall_score(y_true, y_pred, average='macro')\n",
        "    }\n",
        "\n",
        "metrics_nn = calculate_metrics(y_test, y_pred_nn)\n",
        "metrics_gb = calculate_metrics(y_test, y_pred_gb)\n",
        "metrics_rf = calculate_metrics(y_test, y_pred_rf)\n",
        "\n",
        "# Create comparison dataframe\n",
        "comparison_df = pd.DataFrame({\n",
        "    'Neural Network': metrics_nn,\n",
        "    'Gradient Boosting': metrics_gb,\n",
        "    'Random Forest': metrics_rf\n",
        "}).T\n",
        "\n",
        "print(\"Model Performance Comparison:\")\n",
        "display(comparison_df.round(4))"
      ],
      "metadata": {
        "id": "performance_comparison"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize Model Comparison\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "x = np.arange(len(comparison_df.columns))\n",
        "width = 0.25\n",
        "\n",
        "models_list = ['Neural Network', 'Gradient Boosting', 'Random Forest']\n",
        "colors = ['#2ecc71', '#3498db', '#e74c3c']\n",
        "\n",
        "for i, model in enumerate(models_list):\n",
        "    values = comparison_df.loc[model].values * 100\n",
        "    bars = ax.bar(x + i*width, values, width, label=model, color=colors[i])\n",
        "    ax.bar_label(bars, fmt='%.1f%%', fontsize=8)\n",
        "\n",
        "ax.set_ylabel('Score (%)')\n",
        "ax.set_title('Model Performance Comparison')\n",
        "ax.set_xticks(x + width)\n",
        "ax.set_xticklabels(comparison_df.columns, rotation=15, ha='right')\n",
        "ax.legend()\n",
        "ax.set_ylim([0, 110])\n",
        "ax.grid(axis='y', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('model_comparison.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "model_comparison_chart"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Training History (Neural Network)"
      ],
      "metadata": {
        "id": "section_10"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Training History\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Plot Accuracy\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Neural Network - Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.3)\n",
        "\n",
        "# Plot Loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Neural Network - Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('nn_training_history.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "training_history"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11. Summary\n",
        "\n",
        "This project successfully demonstrated the application of neural networks and machine learning classifiers for customer segmentation based on RFM analysis.\n",
        "\n",
        "**Key Findings:**\n",
        "- All three models achieved high accuracy on the customer classification task\n",
        "- The Neural Network model demonstrated excellent performance with minimal overfitting\n",
        "- RFM features proved to be highly effective for customer value segmentation\n",
        "\n",
        "**Customer Segments Identified:**\n",
        "- **Low Value (Cluster 0):** At-risk/churned customers with high recency and low engagement\n",
        "- **Mid Value (Cluster 1):** Regular customers with moderate purchasing behavior\n",
        "- **High Value (Cluster 2):** VIP customers with recent purchases and high monetary value"
      ],
      "metadata": {
        "id": "section_11"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Final Summary Table\n",
        "print(\"=\" * 70)\n",
        "print(\"FINAL MODEL PERFORMANCE SUMMARY\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "summary_data = {\n",
        "    'Model': ['Neural Network', 'Gradient Boosting', 'Random Forest'],\n",
        "    'Accuracy': [f'{nn_accuracy*100:.2f}%', f'{gb_accuracy*100:.2f}%', f'{rf_accuracy*100:.2f}%'],\n",
        "    'F1 Score (Macro)': [\n",
        "        f\"{metrics_nn['F1 (Macro)']*100:.2f}%\",\n",
        "        f\"{metrics_gb['F1 (Macro)']*100:.2f}%\",\n",
        "        f\"{metrics_rf['F1 (Macro)']*100:.2f}%\"\n",
        "    ],\n",
        "    'Precision (Macro)': [\n",
        "        f\"{metrics_nn['Precision (Macro)']*100:.2f}%\",\n",
        "        f\"{metrics_gb['Precision (Macro)']*100:.2f}%\",\n",
        "        f\"{metrics_rf['Precision (Macro)']*100:.2f}%\"\n",
        "    ],\n",
        "    'Recall (Macro)': [\n",
        "        f\"{metrics_nn['Recall (Macro)']*100:.2f}%\",\n",
        "        f\"{metrics_gb['Recall (Macro)']*100:.2f}%\",\n",
        "        f\"{metrics_rf['Recall (Macro)']*100:.2f}%\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "summary_df = pd.DataFrame(summary_data)\n",
        "summary_df.set_index('Model', inplace=True)\n",
        "display(summary_df)"
      ],
      "metadata": {
        "id": "final_summary"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}